{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Flatten, Dense, Dropout, Convolution2D, Conv2D, MaxPooling2D, Lambda, GlobalMaxPooling2D, GlobalAveragePooling2D, BatchNormalization, Activation, AveragePooling2D, Concatenate\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "\n",
    "%matplotlib inline\n",
    "keras.backend.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando o arquivo da base, UCI_Credit_Card.csv, e nomeando cada um dos seus atributos originais como explicado acima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"UCI_Credit_Card.csv\", names = [\"ID\",\"LIMIT_BAL\",\"SEX\",\"EDUCATION\",\"MARRIAGE\",\"AGE\",\"PAY_0\",\"PAY_2\",\"PAY_3\",\"PAY_4\",\"PAY_5\",\"PAY_6\",\"BILL_AMT1\",\"BILL_AMT2\",\"BILL_AMT3\",\"BILL_AMT4\",\"BILL_AMT5\",\"BILL_AMT6\",\"PAY_AMT1\",\"PAY_AMT2\",\"PAY_AMT3\",\"PAY_AMT4\",\"PAY_AMT5\",\"PAY_AMT6\",\"default.payment.next.month\"])\n",
    "df = df.drop([0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_127 (Dense)            (None, 46)                1104      \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 46)                2162      \n",
      "_________________________________________________________________\n",
      "dense_129 (Dense)            (None, 1)                 47        \n",
      "=================================================================\n",
      "Total params: 3,313\n",
      "Trainable params: 3,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(46, activation='relu', input_shape=(2460000,)))\n",
    "model.add(layers.Dense(46, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "def load_data_kfold(k):\n",
    "    \n",
    "    train = df\n",
    "    \n",
    "    X_train = np.array((df.drop('default.payment.next.month', axis=1)).drop('ID', axis=1).values)\n",
    "    \n",
    "    y_train = np.array(train['default.payment.next.month'].values)\n",
    "    \n",
    "    folds = list(StratifiedKFold(n_splits=k, shuffle=True, random_state=1).split(X_train, y_train))\n",
    "    \n",
    "    return folds, X_train, y_train\n",
    "\n",
    "k = 7\n",
    "folds, X_train, y_train = load_data_kfold(k)\n",
    "\n",
    "def get_model():\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    \n",
    "    model.add(layers.Dense(46, activation='relu', input_shape=(23,)))\n",
    "    model.add(layers.Dense(46, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold  0\n",
      "Epoch 1/10\n",
      "25714/25714 [==============================] - 4s 157us/step - loss: 3.5654 - acc: 0.7788\n",
      "Epoch 2/10\n",
      "25714/25714 [==============================] - 2s 86us/step - loss: 3.5654 - acc: 0.7788\n",
      "Epoch 3/10\n",
      "25714/25714 [==============================] - 2s 59us/step - loss: 3.5654 - acc: 0.7788: 0s - loss: 3.5808 - acc: 0.7\n",
      "Epoch 4/10\n",
      "25714/25714 [==============================] - 2s 68us/step - loss: 3.5654 - acc: 0.7788\n",
      "Epoch 5/10\n",
      "25714/25714 [==============================] - 2s 60us/step - loss: 3.5654 - acc: 0.7788\n",
      "Epoch 6/10\n",
      "25714/25714 [==============================] - 1s 54us/step - loss: 3.5654 - acc: 0.7788\n",
      "Epoch 7/10\n",
      "25714/25714 [==============================] - 1s 53us/step - loss: 3.5654 - acc: 0.7788\n",
      "Epoch 8/10\n",
      "25714/25714 [==============================] - 1s 53us/step - loss: 3.5654 - acc: 0.7788\n",
      "Epoch 9/10\n",
      "25714/25714 [==============================] - 1s 57us/step - loss: 3.5654 - acc: 0.7788\n",
      "Epoch 10/10\n",
      "25714/25714 [==============================] - 2s 63us/step - loss: 3.5654 - acc: 0.7788\n",
      "4286/4286 [==============================] - 1s 146us/step\n",
      "Loss: 3.5650850679626322 | Accuracy: 0.7788147458505029\n",
      "\n",
      "Fold  1\n",
      "Epoch 1/10\n",
      "25714/25714 [==============================] - 3s 110us/step - loss: 7.6029 - acc: 0.5242\n",
      "Epoch 2/10\n",
      "25714/25714 [==============================] - 2s 76us/step - loss: 3.5815 - acc: 0.7778\n",
      "Epoch 3/10\n",
      "25714/25714 [==============================] - 3s 106us/step - loss: 3.5815 - acc: 0.7778\n",
      "Epoch 4/10\n",
      "25714/25714 [==============================] - 2s 67us/step - loss: 3.5815 - acc: 0.7778\n",
      "Epoch 5/10\n",
      "25714/25714 [==============================] - 2s 72us/step - loss: 3.5815 - acc: 0.7778\n",
      "Epoch 6/10\n",
      "25714/25714 [==============================] - 2s 92us/step - loss: 3.5815 - acc: 0.7778: 0s - loss: 3.5924 - acc\n",
      "Epoch 7/10\n",
      "25714/25714 [==============================] - 3s 98us/step - loss: 3.5815 - acc: 0.7778\n",
      "Epoch 8/10\n",
      "25714/25714 [==============================] - 2s 69us/step - loss: 3.5815 - acc: 0.7778\n",
      "Epoch 9/10\n",
      "25714/25714 [==============================] - 2s 71us/step - loss: 3.5815 - acc: 0.7778\n",
      "Epoch 10/10\n",
      "25714/25714 [==============================] - 2s 70us/step - loss: 3.5815 - acc: 0.7778\n",
      "4286/4286 [==============================] - 1s 164us/step\n",
      "Loss: 3.579922618901568 | Accuracy: 0.777881474651803\n",
      "\n",
      "Fold  2\n",
      "Epoch 1/10\n",
      "25714/25714 [==============================] - 3s 127us/step - loss: 8.0014 - acc: 0.4989\n",
      "Epoch 2/10\n",
      "25714/25714 [==============================] - 2s 67us/step - loss: 5.4287 - acc: 0.6611\n",
      "Epoch 3/10\n",
      "25714/25714 [==============================] - 2s 66us/step - loss: 3.6897 - acc: 0.7709\n",
      "Epoch 4/10\n",
      "25714/25714 [==============================] - 2s 59us/step - loss: 3.5691 - acc: 0.7786\n",
      "Epoch 5/10\n",
      "25714/25714 [==============================] - 2s 66us/step - loss: 3.5666 - acc: 0.7787\n",
      "Epoch 6/10\n",
      "25714/25714 [==============================] - 2s 73us/step - loss: 3.5666 - acc: 0.7787\n",
      "Epoch 7/10\n",
      "25714/25714 [==============================] - 2s 67us/step - loss: 3.5666 - acc: 0.7787\n",
      "Epoch 8/10\n",
      "25714/25714 [==============================] - 2s 68us/step - loss: 3.5666 - acc: 0.7787\n",
      "Epoch 9/10\n",
      "25714/25714 [==============================] - 2s 64us/step - loss: 3.5666 - acc: 0.7787\n",
      "Epoch 10/10\n",
      "25714/25714 [==============================] - 2s 64us/step - loss: 3.5666 - acc: 0.7787\n",
      "4286/4286 [==============================] - 1s 157us/step\n",
      "Loss: 3.561324410276106 | Accuracy: 0.7790480633511813\n",
      "\n",
      "Fold  3\n",
      "Epoch 1/10\n",
      "25714/25714 [==============================] - 3s 120us/step - loss: 3.5697 - acc: 0.7785\n",
      "Epoch 2/10\n",
      "25714/25714 [==============================] - 2s 65us/step - loss: 3.5697 - acc: 0.7785: 0s - loss: 3.5691 - acc: \n",
      "Epoch 3/10\n",
      "25714/25714 [==============================] - 2s 65us/step - loss: 3.5697 - acc: 0.7785\n",
      "Epoch 4/10\n",
      "25714/25714 [==============================] - 2s 64us/step - loss: 3.5697 - acc: 0.7785\n",
      "Epoch 5/10\n",
      "25714/25714 [==============================] - 2s 63us/step - loss: 3.5697 - acc: 0.7785\n",
      "Epoch 6/10\n",
      "25714/25714 [==============================] - 2s 65us/step - loss: 3.5697 - acc: 0.7785\n",
      "Epoch 7/10\n",
      "25714/25714 [==============================] - 2s 67us/step - loss: 3.5697 - acc: 0.7785\n",
      "Epoch 8/10\n",
      "25714/25714 [==============================] - 2s 67us/step - loss: 3.5697 - acc: 0.7785\n",
      "Epoch 9/10\n",
      "25714/25714 [==============================] - 2s 67us/step - loss: 3.5697 - acc: 0.7785\n",
      "Epoch 10/10\n",
      "25714/25714 [==============================] - 2s 62us/step - loss: 3.5697 - acc: 0.7785\n",
      "4286/4286 [==============================] - 1s 128us/step\n",
      "Loss: 3.5725243369398068 | Accuracy: 0.7783481100425507\n",
      "\n",
      "Fold  4\n",
      "Epoch 1/10\n",
      "25714/25714 [==============================] - 3s 117us/step - loss: 3.5984 - acc: 0.7767\n",
      "Epoch 2/10\n",
      "25714/25714 [==============================] - 2s 62us/step - loss: 3.5783 - acc: 0.7780\n",
      "Epoch 3/10\n",
      "25714/25714 [==============================] - 2s 67us/step - loss: 3.5783 - acc: 0.7780\n",
      "Epoch 4/10\n",
      "25714/25714 [==============================] - 2s 63us/step - loss: 3.5783 - acc: 0.7780\n",
      "Epoch 5/10\n",
      "25714/25714 [==============================] - 2s 65us/step - loss: 3.5783 - acc: 0.7780\n",
      "Epoch 6/10\n",
      "25714/25714 [==============================] - 2s 64us/step - loss: 3.5783 - acc: 0.7780\n",
      "Epoch 7/10\n",
      "25714/25714 [==============================] - 2s 71us/step - loss: 3.5783 - acc: 0.7780\n",
      "Epoch 8/10\n",
      "25714/25714 [==============================] - 2s 66us/step - loss: 3.5783 - acc: 0.7780\n",
      "Epoch 9/10\n",
      "25714/25714 [==============================] - 2s 73us/step - loss: 3.5783 - acc: 0.7780\n",
      "Epoch 10/10\n",
      "25714/25714 [==============================] - 3s 103us/step - loss: 3.5783 - acc: 0.7780\n",
      "4286/4286 [==============================] - 1s 285us/step\n",
      "Loss: 3.576243986774147 | Accuracy: 0.7781147922359223\n",
      "\n",
      "Fold  5\n",
      "Epoch 1/10\n",
      "25715/25715 [==============================] - 6s 234us/step - loss: 4.4890 - acc: 0.7206\n",
      "Epoch 2/10\n",
      "25715/25715 [==============================] - 2s 94us/step - loss: 3.5652 - acc: 0.7788\n",
      "Epoch 3/10\n",
      "25715/25715 [==============================] - 3s 97us/step - loss: 3.5652 - acc: 0.7788\n",
      "Epoch 4/10\n",
      "25715/25715 [==============================] - 2s 97us/step - loss: 3.5652 - acc: 0.7788\n",
      "Epoch 5/10\n",
      "25715/25715 [==============================] - 3s 103us/step - loss: 3.5652 - acc: 0.7788 1s\n",
      "Epoch 6/10\n",
      "25715/25715 [==============================] - 2s 83us/step - loss: 3.5652 - acc: 0.7788\n",
      "Epoch 7/10\n",
      "25715/25715 [==============================] - 2s 71us/step - loss: 3.5652 - acc: 0.7788\n",
      "Epoch 8/10\n",
      "25715/25715 [==============================] - ETA: 0s - loss: 3.5590 - acc: 0.779 - 3s 111us/step - loss: 3.5652 - acc: 0.7788\n",
      "Epoch 9/10\n",
      "25715/25715 [==============================] - ETA: 0s - loss: 3.5596 - acc: 0.779 - 2s 97us/step - loss: 3.5652 - acc: 0.7788\n",
      "Epoch 10/10\n",
      "25715/25715 [==============================] - 3s 104us/step - loss: 3.5652 - acc: 0.7788\n",
      "4285/4285 [==============================] - 1s 257us/step\n",
      "Loss: 3.5659170377212757 | Accuracy: 0.7787631273686956\n",
      "\n",
      "Fold  6\n",
      "Epoch 1/10\n",
      "25715/25715 [==============================] - 5s 195us/step - loss: 4.8210 - acc: 0.6995\n",
      "Epoch 2/10\n",
      "25715/25715 [==============================] - 3s 111us/step - loss: 3.5930 - acc: 0.7771\n",
      "Epoch 3/10\n",
      "25715/25715 [==============================] - 3s 106us/step - loss: 3.5930 - acc: 0.7771\n",
      "Epoch 4/10\n",
      "25715/25715 [==============================] - 2s 69us/step - loss: 3.5930 - acc: 0.7771\n",
      "Epoch 5/10\n",
      "25715/25715 [==============================] - 2s 80us/step - loss: 3.5930 - acc: 0.7771\n",
      "Epoch 6/10\n",
      "25715/25715 [==============================] - 2s 85us/step - loss: 3.5930 - acc: 0.7771\n",
      "Epoch 7/10\n",
      "25715/25715 [==============================] - 2s 87us/step - loss: 3.5930 - acc: 0.7771\n",
      "Epoch 8/10\n",
      "25715/25715 [==============================] - 2s 94us/step - loss: 3.5930 - acc: 0.7771\n",
      "Epoch 9/10\n",
      "25715/25715 [==============================] - 2s 91us/step - loss: 3.5930 - acc: 0.7771\n",
      "Epoch 10/10\n",
      "25715/25715 [==============================] - 2s 93us/step - loss: 3.5930 - acc: 0.7771\n",
      "4285/4285 [==============================] - 1s 248us/step\n",
      "Loss: 3.591755566626017 | Accuracy: 0.7771295213921902\n"
     ]
    }
   ],
   "source": [
    "Keras_Accuracy_Antes = 0\n",
    "Keras_Loss_Antes = 0\n",
    "\n",
    "for j, (train_idx, val_idx) in enumerate(folds):\n",
    "    \n",
    "    print('\\nFold ',j)\n",
    "    X_train_cv = X_train[train_idx]\n",
    "    y_train_cv = y_train[train_idx]\n",
    "    X_valid_cv = X_train[val_idx]\n",
    "    y_valid_cv= y_train[val_idx]\n",
    "    \n",
    "    name_weights = \"final_model_fold\" + str(j) + \"_weights.h5\"\n",
    "    model = get_model()\n",
    "    model.fit(X_train_cv,\n",
    "              y_train_cv,\n",
    "              epochs=10,\n",
    "              batch_size=32)\n",
    "    \n",
    "    test_loss, test_accuracy = model.evaluate(X_valid_cv, y_valid_cv)\n",
    "    \n",
    "    Keras_Accuracy_Antes = (Keras_Accuracy_Antes + test_accuracy)\n",
    "    Keras_Loss_Antes = (Keras_Loss_Antes + test_loss)\n",
    "    \n",
    "    print(\"Loss: %s | Accuracy: %s\" % (test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7782999764132636\n",
      "3.5732532893145073\n"
     ]
    }
   ],
   "source": [
    "    Keras_Accuracy_Antes = Keras_Accuracy_Antes/k\n",
    "    Keras_Loss_Antes = Keras_Loss_Antes/k\n",
    "    print(Keras_Accuracy_Antes)\n",
    "    print(Keras_Loss_Antes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lendo csv pré-processado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>BILL_AMT1</th>\n",
       "      <th>BILL_AMT2</th>\n",
       "      <th>BILL_AMT3</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>...</th>\n",
       "      <th>PAY_6_D1</th>\n",
       "      <th>PAY_6_D2</th>\n",
       "      <th>PAY_6_D3</th>\n",
       "      <th>PAY_6_D4</th>\n",
       "      <th>PAY_6_D5</th>\n",
       "      <th>PAY_6_D6</th>\n",
       "      <th>PAY_6_D7</th>\n",
       "      <th>PAY_6_D8</th>\n",
       "      <th>PAY_6_D9</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0</td>\n",
       "      <td>0.051724</td>\n",
       "      <td>0.149982</td>\n",
       "      <td>0.069164</td>\n",
       "      <td>0.086723</td>\n",
       "      <td>0.160138</td>\n",
       "      <td>0.080648</td>\n",
       "      <td>0.260979</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0</td>\n",
       "      <td>0.086207</td>\n",
       "      <td>0.148892</td>\n",
       "      <td>0.067858</td>\n",
       "      <td>0.087817</td>\n",
       "      <td>0.163220</td>\n",
       "      <td>0.084074</td>\n",
       "      <td>0.263485</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.080808</td>\n",
       "      <td>0</td>\n",
       "      <td>0.224138</td>\n",
       "      <td>0.172392</td>\n",
       "      <td>0.079532</td>\n",
       "      <td>0.093789</td>\n",
       "      <td>0.173637</td>\n",
       "      <td>0.095470</td>\n",
       "      <td>0.272928</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.040404</td>\n",
       "      <td>0</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.188100</td>\n",
       "      <td>0.111995</td>\n",
       "      <td>0.113407</td>\n",
       "      <td>0.186809</td>\n",
       "      <td>0.109363</td>\n",
       "      <td>0.283685</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.040404</td>\n",
       "      <td>1</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.154144</td>\n",
       "      <td>0.071601</td>\n",
       "      <td>0.106020</td>\n",
       "      <td>0.179863</td>\n",
       "      <td>0.099633</td>\n",
       "      <td>0.275681</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  LIMIT_BAL  SEX       AGE  BILL_AMT1  BILL_AMT2  BILL_AMT3  BILL_AMT4  \\\n",
       "0   1   0.010101    0  0.051724   0.149982   0.069164   0.086723   0.160138   \n",
       "1   2   0.111111    0  0.086207   0.148892   0.067858   0.087817   0.163220   \n",
       "2   3   0.080808    0  0.224138   0.172392   0.079532   0.093789   0.173637   \n",
       "3   4   0.040404    0  0.275862   0.188100   0.111995   0.113407   0.186809   \n",
       "4   5   0.040404    1  0.620690   0.154144   0.071601   0.106020   0.179863   \n",
       "\n",
       "   BILL_AMT5  BILL_AMT6  ...  PAY_6_D1  PAY_6_D2  PAY_6_D3  PAY_6_D4  \\\n",
       "0   0.080648   0.260979  ...         0         0         0         0   \n",
       "1   0.084074   0.263485  ...         0         1         0         0   \n",
       "2   0.095470   0.272928  ...         0         0         0         0   \n",
       "3   0.109363   0.283685  ...         0         0         0         0   \n",
       "4   0.099633   0.275681  ...         0         0         0         0   \n",
       "\n",
       "   PAY_6_D5  PAY_6_D6  PAY_6_D7  PAY_6_D8  PAY_6_D9  Class  \n",
       "0         0         0         0         0         0      1  \n",
       "1         0         0         0         0         0      1  \n",
       "2         0         0         0         0         0      0  \n",
       "3         0         0         0         0         0      0  \n",
       "4         0         0         0         0         0      0  \n",
       "\n",
       "[5 rows x 84 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"credit_preprocessed.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n",
    "df = df.drop('ID', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicando Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_154 (Dense)            (None, 46)                3818      \n",
      "_________________________________________________________________\n",
      "dense_155 (Dense)            (None, 46)                2162      \n",
      "_________________________________________________________________\n",
      "dense_156 (Dense)            (None, 1)                 47        \n",
      "=================================================================\n",
      "Total params: 6,027\n",
      "Trainable params: 6,027\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(46, activation='relu', input_shape=(2460000,)))\n",
    "model.add(layers.Dense(46, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "def load_data_kfold(k):\n",
    "    \n",
    "    train = df\n",
    "    \n",
    "    X_train = np.array(df.drop('Class', axis=1).values)\n",
    "    \n",
    "    y_train = np.array(train[\"Class\"].values)\n",
    "    \n",
    "    folds = list(StratifiedKFold(n_splits=k, shuffle=True, random_state=1).split(X_train, y_train))\n",
    "    \n",
    "    return folds, X_train, y_train\n",
    "\n",
    "k = 7\n",
    "folds, X_train, y_train = load_data_kfold(k)\n",
    "\n",
    "def get_model():\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    \n",
    "    model.add(layers.Dense(46, activation='relu', input_shape=(82,)))\n",
    "    model.add(layers.Dense(46, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold  0\n",
      "Epoch 1/10\n",
      "25714/25714 [==============================] - 5s 195us/step - loss: 0.4519 - acc: 0.8140\n",
      "Epoch 2/10\n",
      "25714/25714 [==============================] - 2s 60us/step - loss: 0.4377 - acc: 0.8211: 0s - loss: 0.43\n",
      "Epoch 3/10\n",
      "25714/25714 [==============================] - 2s 61us/step - loss: 0.4357 - acc: 0.8225\n",
      "Epoch 4/10\n",
      "25714/25714 [==============================] - 2s 77us/step - loss: 0.4353 - acc: 0.8223\n",
      "Epoch 5/10\n",
      "25714/25714 [==============================] - 2s 80us/step - loss: 0.4350 - acc: 0.8217\n",
      "Epoch 6/10\n",
      "25714/25714 [==============================] - 2s 75us/step - loss: 0.4338 - acc: 0.8226: 0s - loss: 0.4346 - acc: 0.8\n",
      "Epoch 7/10\n",
      "25714/25714 [==============================] - 2s 69us/step - loss: 0.4336 - acc: 0.8231\n",
      "Epoch 8/10\n",
      "25714/25714 [==============================] - 2s 60us/step - loss: 0.4332 - acc: 0.8236\n",
      "Epoch 9/10\n",
      "25714/25714 [==============================] - 1s 57us/step - loss: 0.4327 - acc: 0.8238\n",
      "Epoch 10/10\n",
      "25714/25714 [==============================] - 2s 59us/step - loss: 0.4322 - acc: 0.8239\n",
      "4286/4286 [==============================] - 1s 174us/step\n",
      "Loss: 0.4352697928375693 | Accuracy: 0.8184787679986869\n",
      "\n",
      "Fold  1\n",
      "Epoch 1/10\n",
      "25714/25714 [==============================] - 4s 152us/step - loss: 0.4539 - acc: 0.8122\n",
      "Epoch 2/10\n",
      "25714/25714 [==============================] - 2s 67us/step - loss: 0.4389 - acc: 0.8201\n",
      "Epoch 3/10\n",
      "25714/25714 [==============================] - 2s 85us/step - loss: 0.4366 - acc: 0.8212\n",
      "Epoch 4/10\n",
      "25714/25714 [==============================] - 3s 109us/step - loss: 0.4360 - acc: 0.8222\n",
      "Epoch 5/10\n",
      "25714/25714 [==============================] - 2s 91us/step - loss: 0.4357 - acc: 0.8221\n",
      "Epoch 6/10\n",
      "25714/25714 [==============================] - 2s 92us/step - loss: 0.4349 - acc: 0.8215\n",
      "Epoch 7/10\n",
      "25714/25714 [==============================] - 2s 79us/step - loss: 0.4344 - acc: 0.8223\n",
      "Epoch 8/10\n",
      "25714/25714 [==============================] - 2s 76us/step - loss: 0.4340 - acc: 0.8222\n",
      "Epoch 9/10\n",
      "25714/25714 [==============================] - 2s 62us/step - loss: 0.4335 - acc: 0.8233\n",
      "Epoch 10/10\n",
      "25714/25714 [==============================] - 2s 79us/step - loss: 0.4332 - acc: 0.8235: 0s - loss: 0.4342 - acc: 0.82 - ETA: 0s - loss: 0.4329 - acc: 0.823\n",
      "4286/4286 [==============================] - 1s 248us/step\n",
      "Loss: 0.4328765491014099 | Accuracy: 0.8229118059074216\n",
      "\n",
      "Fold  2\n",
      "Epoch 1/10\n",
      "25714/25714 [==============================] - 4s 167us/step - loss: 0.4543 - acc: 0.8115\n",
      "Epoch 2/10\n",
      "25714/25714 [==============================] - ETA: 0s - loss: 0.4379 - acc: 0.820 - 2s 89us/step - loss: 0.4378 - acc: 0.8209\n",
      "Epoch 3/10\n",
      "25714/25714 [==============================] - 2s 85us/step - loss: 0.4358 - acc: 0.8226\n",
      "Epoch 4/10\n",
      "25714/25714 [==============================] - 2s 86us/step - loss: 0.4353 - acc: 0.8217\n",
      "Epoch 5/10\n",
      "25714/25714 [==============================] - 2s 83us/step - loss: 0.4338 - acc: 0.8223\n",
      "Epoch 6/10\n",
      "25714/25714 [==============================] - 2s 72us/step - loss: 0.4339 - acc: 0.8232\n",
      "Epoch 7/10\n",
      "25714/25714 [==============================] - 2s 65us/step - loss: 0.4334 - acc: 0.8237\n",
      "Epoch 8/10\n",
      "25714/25714 [==============================] - 2s 94us/step - loss: 0.4327 - acc: 0.8233\n",
      "Epoch 9/10\n",
      "25714/25714 [==============================] - 2s 90us/step - loss: 0.4321 - acc: 0.8238\n",
      "Epoch 10/10\n",
      "25714/25714 [==============================] - 2s 97us/step - loss: 0.4321 - acc: 0.8241\n",
      "4286/4286 [==============================] - 1s 272us/step\n",
      "Loss: 0.44390561313090676 | Accuracy: 0.819178721502013\n",
      "\n",
      "Fold  3\n",
      "Epoch 1/10\n",
      "25714/25714 [==============================] - 5s 202us/step - loss: 0.4554 - acc: 0.8083\n",
      "Epoch 2/10\n",
      "25714/25714 [==============================] - 3s 108us/step - loss: 0.4368 - acc: 0.8208 1s - loss\n",
      "Epoch 3/10\n",
      "25714/25714 [==============================] - 3s 107us/step - loss: 0.4355 - acc: 0.8216\n",
      "Epoch 4/10\n",
      "25714/25714 [==============================] - 2s 69us/step - loss: 0.4342 - acc: 0.8216\n",
      "Epoch 5/10\n",
      "25714/25714 [==============================] - 2s 79us/step - loss: 0.4334 - acc: 0.8228\n",
      "Epoch 6/10\n",
      "25714/25714 [==============================] - 3s 108us/step - loss: 0.4331 - acc: 0.8223\n",
      "Epoch 7/10\n",
      "25714/25714 [==============================] - 3s 127us/step - loss: 0.4326 - acc: 0.8231\n",
      "Epoch 8/10\n",
      "25714/25714 [==============================] - 3s 111us/step - loss: 0.4321 - acc: 0.8224\n",
      "Epoch 9/10\n",
      "25714/25714 [==============================] - 3s 109us/step - loss: 0.4317 - acc: 0.8230\n",
      "Epoch 10/10\n",
      "25714/25714 [==============================] - 3s 111us/step - loss: 0.4314 - acc: 0.8230\n",
      "4286/4286 [==============================] - 1s 330us/step\n",
      "Loss: 0.44429461537706927 | Accuracy: 0.818012132635753\n",
      "\n",
      "Fold  4\n",
      "Epoch 1/10\n",
      "25714/25714 [==============================] - 5s 184us/step - loss: 0.4515 - acc: 0.8117\n",
      "Epoch 2/10\n",
      "25714/25714 [==============================] - 2s 61us/step - loss: 0.4379 - acc: 0.8193\n",
      "Epoch 3/10\n",
      "25714/25714 [==============================] - 2s 96us/step - loss: 0.4364 - acc: 0.8216: 0s - loss: 0.4390 - a\n",
      "Epoch 4/10\n",
      "25714/25714 [==============================] - 3s 112us/step - loss: 0.4354 - acc: 0.8222\n",
      "Epoch 5/10\n",
      "25714/25714 [==============================] - 3s 102us/step - loss: 0.4349 - acc: 0.8218\n",
      "Epoch 6/10\n",
      "25714/25714 [==============================] - 3s 103us/step - loss: 0.4344 - acc: 0.8224\n",
      "Epoch 7/10\n",
      "25714/25714 [==============================] - 3s 112us/step - loss: 0.4336 - acc: 0.8217\n",
      "Epoch 8/10\n",
      "25714/25714 [==============================] - 3s 110us/step - loss: 0.4336 - acc: 0.8221\n",
      "Epoch 9/10\n",
      "25714/25714 [==============================] - 3s 110us/step - loss: 0.4331 - acc: 0.8223\n",
      "Epoch 10/10\n",
      "25714/25714 [==============================] - 3s 107us/step - loss: 0.4329 - acc: 0.8234\n",
      "4286/4286 [==============================] - 1s 221us/step\n",
      "Loss: 0.4371643457048917 | Accuracy: 0.8231451235193545\n",
      "\n",
      "Fold  5\n",
      "Epoch 1/10\n",
      "25715/25715 [==============================] - 4s 173us/step - loss: 0.4543 - acc: 0.8110 1s - loss: 0.4623 \n",
      "Epoch 2/10\n",
      "25715/25715 [==============================] - 3s 111us/step - loss: 0.4387 - acc: 0.8200\n",
      "Epoch 3/10\n",
      "25715/25715 [==============================] - 3s 110us/step - loss: 0.4362 - acc: 0.8207\n",
      "Epoch 4/10\n",
      "25715/25715 [==============================] - 3s 118us/step - loss: 0.4365 - acc: 0.8212\n",
      "Epoch 5/10\n",
      "25715/25715 [==============================] - 3s 112us/step - loss: 0.4351 - acc: 0.8220\n",
      "Epoch 6/10\n",
      "25715/25715 [==============================] - 3s 116us/step - loss: 0.4351 - acc: 0.8215\n",
      "Epoch 7/10\n",
      "25715/25715 [==============================] - 3s 106us/step - loss: 0.4337 - acc: 0.8219\n",
      "Epoch 8/10\n",
      "25715/25715 [==============================] - 3s 111us/step - loss: 0.4334 - acc: 0.8220\n",
      "Epoch 9/10\n",
      "25715/25715 [==============================] - 2s 66us/step - loss: 0.4329 - acc: 0.8225: 1s -\n",
      "Epoch 10/10\n",
      "25715/25715 [==============================] - 2s 80us/step - loss: 0.4324 - acc: 0.8226\n",
      "4285/4285 [==============================] - 1s 308us/step\n",
      "Loss: 0.4378216005470538 | Accuracy: 0.8224037338582888\n",
      "\n",
      "Fold  6\n",
      "Epoch 1/10\n",
      "25715/25715 [==============================] - 6s 222us/step - loss: 0.4545 - acc: 0.8109\n",
      "Epoch 2/10\n",
      "25715/25715 [==============================] - 3s 120us/step - loss: 0.4376 - acc: 0.8204\n",
      "Epoch 3/10\n",
      "25715/25715 [==============================] - 3s 121us/step - loss: 0.4363 - acc: 0.8217\n",
      "Epoch 4/10\n",
      "25715/25715 [==============================] - 3s 117us/step - loss: 0.4358 - acc: 0.8220\n",
      "Epoch 5/10\n",
      "25715/25715 [==============================] - 3s 114us/step - loss: 0.4352 - acc: 0.8224\n",
      "Epoch 6/10\n",
      "25715/25715 [==============================] - 3s 102us/step - loss: 0.4347 - acc: 0.8216\n",
      "Epoch 7/10\n",
      "25715/25715 [==============================] - 2s 88us/step - loss: 0.4340 - acc: 0.8234\n",
      "Epoch 8/10\n",
      "25715/25715 [==============================] - 2s 64us/step - loss: 0.4333 - acc: 0.8227\n",
      "Epoch 9/10\n",
      "25715/25715 [==============================] - 2s 62us/step - loss: 0.4330 - acc: 0.8228\n",
      "Epoch 10/10\n",
      "25715/25715 [==============================] - 2s 62us/step - loss: 0.4323 - acc: 0.8229\n",
      "4285/4285 [==============================] - 1s 186us/step\n",
      "Loss: 0.4399804095682213 | Accuracy: 0.8184364059981276\n"
     ]
    }
   ],
   "source": [
    "Keras_Accuracy = 0\n",
    "Keras_Loss = 0\n",
    "\n",
    "for j, (train_idx, val_idx) in enumerate(folds):\n",
    "    \n",
    "    print('\\nFold ',j)\n",
    "    X_train_cv = X_train[train_idx]\n",
    "    y_train_cv = y_train[train_idx]\n",
    "    X_valid_cv = X_train[val_idx]\n",
    "    y_valid_cv= y_train[val_idx]\n",
    "    \n",
    "    name_weights = \"final_model_fold\" + str(j) + \"_weights.h5\"\n",
    "#     callbacks = get_callbacks(name_weights = name_weights, patience_lr=10)\n",
    "#     generator = gen.flow(X_train_cv, y_train_cv, batch_size = batch_size)\n",
    "    model = get_model()\n",
    "    model.fit(X_train_cv,\n",
    "              y_train_cv,\n",
    "              epochs=10,\n",
    "              batch_size=32)\n",
    "    \n",
    "    test_loss, test_accuracy = model.evaluate(X_valid_cv, y_valid_cv)\n",
    "    Keras_Accuracy = (Keras_Accuracy + test_accuracy)\n",
    "    Keras_Loss = (Keras_Loss + test_loss)\n",
    "    print(\"Loss: %s | Accuracy: %s\" % (test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8203666702028064\n",
      "0.4387589894667317\n"
     ]
    }
   ],
   "source": [
    "    Keras_Accuracy = Keras_Accuracy/k\n",
    "    Keras_Loss = Keras_Loss/k\n",
    "    print(Keras_Accuracy)\n",
    "    print(Keras_Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"credit_preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparação de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antes \n",
      "Accuracy: 0.78  e Loss: 3.57 \n",
      "Depois \n",
      "Accuracy: 0.82  e Loss: 0.44\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = {'Antes':[Keras_Accuracy_Antes, Keras_Loss_Antes],\n",
    "        'Depois':[Keras_Accuracy, Keras_Loss]} \n",
    "\n",
    "print(\"Antes \\nAccuracy: %.2f  e Loss: %.2f \\nDepois \\nAccuracy: %.2f  e Loss: %.2f\" % (Keras_Accuracy_Antes, Keras_Loss_Antes, Keras_Accuracy, Keras_Loss))\n",
    "\n",
    "# Creates pandas DataFrame. \n",
    "dfResultados = pd.DataFrame(data, index =['Accuracy', 'Loss']) \n",
    "\n",
    "ax = dfResultados.plot.bar(rot=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
